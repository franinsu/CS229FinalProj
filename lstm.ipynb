{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.objectives import mean_squared_error\n",
    "import keras.backend as K\n",
    "import keras\n",
    "import csv,os, glob\n",
    "import random\n",
    "import pickle\n",
    "from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size train: 33539\n",
      "Size dev: 3946\n",
      "Size test: 1973\n",
      "X_train shape: (37485, 2048, 2)\n"
     ]
    }
   ],
   "source": [
    "XY=np.load(\"/gpfs/slac/staas/fs1/g/supercdms/tf/northwestern/users/franinsu/testRun3/XY60k.npz\")\n",
    "X=XY[\"X\"]\n",
    "Y=XY[\"Y\"]\n",
    "Yrange = np.array([2048,20])# Ymax-Ymin\n",
    "downsample_factor = 1\n",
    "N=len(X)\n",
    "X=X.reshape(-1,2048,2)\n",
    "X = np.array([np.mean(x.reshape(-1, downsample_factor,2), 1) for x in X])\n",
    "m_train = round(.95*N)\n",
    "m_dev =  round(10/95*m_train)\n",
    "idx = np.random.permutation(N)\n",
    "X_train, X_test = X[idx[:m_train]], X[idx[m_train:]]\n",
    "Y_train, Y_test = Y[idx[:m_train]], Y[idx[m_train:]]\n",
    "#dev is subset of train but isn't actually used in training\n",
    "X_dev, Y_dev  = X_train[-m_dev:], Y_train[-m_dev:]\n",
    "print(\"Size train:\",X_train.shape[0]-X_dev.shape[0])\n",
    "print(\"Size dev:\",X_dev.shape[0])\n",
    "print(\"Size test:\", X_test.shape[0])\n",
    "print(\"X_train shape:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_size = 8\n",
    "conv_stride = 8\n",
    "input_channels = X_train.shape[2]\n",
    "output_filters = 32\n",
    "conv_weights = tf.Variable(tf.random_normal([filter_size, input_channels, output_filters]))\n",
    "max_pool_size = 6\n",
    "max_pool_stride = 6\n",
    "conv_bias = tf.Variable(tf.random_normal([output_filters]))\n",
    "#define constants\n",
    "#unrolled through 28 time steps\n",
    "time_steps=X_train.shape[1] # TO EDIT\n",
    "#hidden LSTM units\n",
    "num_units=256\n",
    "n_input=X_train.shape[2] # TO EDIT\n",
    "#learning rate for adam\n",
    "learning_rate=0.001\n",
    "#size of batch\n",
    "# batch_size=128\n",
    "n_out = 1\n",
    "#weights and biases of appropriate shape to accomplish above task\n",
    "seed = 35\n",
    "initializer = tf.contrib.layers.xavier_initializer(seed=seed)\n",
    "#defining placeholders\n",
    "#input image placeholder\n",
    "x=tf.placeholder(\"float\",[None,time_steps,n_input])\n",
    "#input label placeholder\n",
    "y=tf.placeholder(\"float\",[None,n_out])\n",
    "device_name = \"/device:GPU:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_units: 42\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/device:GPU:0\"):\n",
    "    input = x\n",
    "    conv = tf.nn.conv1d(input,conv_weights,stride = conv_stride,padding='VALID') + conv_bias\n",
    "    max_pool = tf.nn.max_pool([conv],\n",
    "       ksize=[1, 1, max_pool_size, 1],\n",
    "       strides=[1,1,max_pool_stride,1],\n",
    "       padding='VALID')[0]\n",
    "    unstacked = tf.unstack(max_pool,axis=1)\n",
    "    num_units = int(max_pool.shape[1])\n",
    "    out_weights=tf.Variable(initializer([num_units,16]))\n",
    "    out_weights2=tf.Variable(initializer([16,n_out]))\n",
    "    out_bias=tf.Variable(initializer([16]))\n",
    "    out_bias2=tf.Variable(initializer([n_out]))\n",
    "    print('num_units:',num_units)\n",
    "    lstm_layer1 = tf.nn.rnn_cell.LSTMCell(num_units,forget_bias=1,name='basic_lstm_cell1')\n",
    "    lstm_layer2 = tf.nn.rnn_cell.LSTMCell(num_units,forget_bias=1,name='basic_lstm_cell2')\n",
    "    outputs1,_=rnn.static_rnn(lstm_layer1,unstacked,dtype=\"float32\")\n",
    "    outputs2,_=rnn.static_rnn(lstm_layer2,outputs1,dtype=\"float32\")\n",
    "    preprediction=tf.matmul(outputs2[-1],out_weights)+out_bias\n",
    "    prediction=tf.matmul(preprediction,out_weights2)+out_bias2\n",
    "    #loss_function\n",
    "    loss=tf.losses.mean_squared_error(predictions=prediction,labels=y)\n",
    "    #optimization\n",
    "    opt=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "def mae(x_e,y_e):\n",
    "    print(\"MAE:\",np.mean(np.abs(sess.run(prediction,feed_dict={x:x_e,y:y_e})-y_e)))\n",
    "#initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "m_training = m_train-m_dev\n",
    "batch_size = 10\n",
    "n_iters = round(m_training/batch_size - 0.5)\n",
    "EPOCHS = 400\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True,log_device_placement=True)) as sess:\n",
    "    sess.run(init)\n",
    "    for j in range(EPOCHS):\n",
    "        iter=0\n",
    "        while iter<n_iters:\n",
    "#            if iter % 5 ==0: print('.',end=\"\")\n",
    "#            if iter % 100==0: print(\"\")\n",
    "            batch_x = X_train[iter*batch_size:(iter+1)*batch_size]\n",
    "            batch_y = Y_train[iter*batch_size:(iter+1)*batch_size,0:1]\n",
    "            batch_x=batch_x.reshape((batch_size,time_steps,n_input))\n",
    "            sess.run(opt, feed_dict={x: batch_x, y: batch_y})\n",
    "            iter=iter+1\n",
    "        if j % 1 ==0:\n",
    "            #los=sess.run(loss,feed_dict={x:X_train[:-m_dev],y:Y_train[:-m_dev,0:1]})\n",
    "            mae(X_train[:-m_dev],Y_train[:-m_dev,0:1])\n",
    "            mae(X_train[-m_dev:],Y_train[-m_dev:,0:1])\n",
    "            #mae=sess.run(score,feed_dict={x:X_train[:-m_dev],y:Y_train[:-m_dev,0:1],prob:0})\n",
    "            print(\"For Epoch \", j)\n",
    "            #print(\"MAE: \",mae)\n",
    "            #print(\"Loss \",los)\n",
    "            print(\"__________________\")\n",
    "\n",
    "    mae(X_train[:-m_dev],Y_train[:-m_dev,0:1])\n",
    "    mae(X_dev,Y_dev[:,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SLAC_Stack (Python 3.6 SCL)",
   "language": "python",
   "name": "slac_stack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
